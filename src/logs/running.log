W0506 23:51:17.733389 39440 torch/distributed/run.py:793] 
W0506 23:51:17.733389 39440 torch/distributed/run.py:793] *****************************************
W0506 23:51:17.733389 39440 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0506 23:51:17.733389 39440 torch/distributed/run.py:793] *****************************************
Data loading | DONE!
Data loading | DONE!
mode:  adaptive
2025-05-06 23:51:20,485 INFO     -------------------------
2025-05-06 23:51:20,485 INFO     | Pre-train Generator
2025-05-06 23:51:20,485 INFO     -------------------------
mode:  adaptive
2025-05-06 23:51:20,629 INFO     >>>>> Generator: Training
2025-05-06 23:51:26,873 INFO     [E1000] Total: 1.753567 | Main: 2.115968 | Aux: 0.876897
2025-05-06 23:51:32,190 INFO     [E2000] Total: 1.716747 | Main: 2.071189 | Aux: 0.856345
2025-05-06 23:51:37,468 INFO     [E3000] Total: 1.708472 | Main: 2.061002 | Aux: 0.851481
2025-05-06 23:51:42,768 INFO     [E4000] Total: 1.703155 | Main: 2.054642 | Aux: 0.848874
2025-05-06 23:51:48,130 INFO     [E5000] Total: 1.698934 | Main: 2.049432 | Aux: 0.846542
2025-05-06 23:51:53,488 INFO     [E6000] Total: 1.694954 | Main: 2.044610 | Aux: 0.844820
2025-05-06 23:51:58,850 INFO     [E7000] Total: 1.692147 | Main: 2.041161 | Aux: 0.843023
2025-05-06 23:52:04,201 INFO     [E8000] Total: 1.690966 | Main: 2.039895 | Aux: 0.843729
2025-05-06 23:52:09,550 INFO     [E9000] Total: 1.689153 | Main: 2.037632 | Aux: 0.841621
2025-05-06 23:52:14,893 INFO     [E10000] Total: 1.687837 | Main: 2.036146 | Aux: 0.840380
2025-05-06 23:52:14,894 INFO     -------------------------
2025-05-06 23:52:14,894 INFO     | EM Iteration: 1/1
2025-05-06 23:52:14,894 INFO     -------------------------
2025-05-06 23:52:14,894 INFO     >>>>> Generator: Rule generation with sampling
2025-05-06 23:52:15,002 INFO     Predictor: read 196 rules from list.
2025-05-06 23:52:15,003 INFO     Initializing distributed process group
2025-05-06 23:52:15,021 INFO     Predictor: read 196 rules from list.
2025-05-06 23:52:15,024 INFO     Preprocess training set
2025-05-06 23:52:15,096 INFO     >>>>> Predictor: Training
[rank1]:[W506 23:52:15.523013844 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank0]:[W506 23:52:15.558255432 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
2025-05-06 23:52:16,575 INFO     100 11892 11.183295 606488.0
2025-05-06 23:52:17,706 INFO     200 11892 11.100737 606488.0
2025-05-06 23:52:18,808 INFO     300 11892 11.015523 606488.0
2025-05-06 23:52:19,917 INFO     400 11892 10.956201 606488.0
2025-05-06 23:52:21,027 INFO     500 11892 10.829840 606488.0
2025-05-06 23:52:22,151 INFO     600 11892 10.797630 606488.0
2025-05-06 23:52:23,248 INFO     700 11892 10.737091 606488.0
2025-05-06 23:52:24,356 INFO     800 11892 10.681332 606488.0
2025-05-06 23:52:25,545 INFO     900 11892 10.623001 606488.0
2025-05-06 23:52:26,670 INFO     1000 11892 10.590147 606488.0
2025-05-06 23:52:26,670 INFO     >>>>> Predictor: Evaluating on valid
2025-05-06 23:53:05,667 INFO     Data : 21135
2025-05-06 23:53:05,668 INFO     Hit1 : 0.012486
2025-05-06 23:53:05,668 INFO     Hit3 : 0.021709
2025-05-06 23:53:05,668 INFO     Hit10: 0.039115
2025-05-06 23:53:05,668 INFO     MR   : 13993.224873
2025-05-06 23:53:05,668 INFO     MRR  : 0.023246
2025-05-06 23:53:05,669 INFO     >>>>> Predictor: Evaluating on test
2025-05-06 23:53:21,961 INFO     Data : 10871
2025-05-06 23:53:21,961 INFO     Hit1 : 0.008089
2025-05-06 23:53:21,961 INFO     Hit3 : 0.015718
2025-05-06 23:53:21,961 INFO     Hit10: 0.034194
2025-05-06 23:53:21,961 INFO     MR   : 12934.914744
2025-05-06 23:53:21,961 INFO     MRR  : 0.018793
2025-05-06 23:53:21,962 INFO     >>>>> Predictor: Computing H scores of rules
2025-05-06 23:53:31,017 INFO     1000 11892
2025-05-06 23:53:40,090 INFO     2000 11892
2025-05-06 23:53:49,103 INFO     3000 11892
2025-05-06 23:53:58,164 INFO     4000 11892
2025-05-06 23:54:07,246 INFO     5000 11892
2025-05-06 23:54:16,458 INFO     6000 11892
2025-05-06 23:54:25,485 INFO     7000 11892
2025-05-06 23:54:34,525 INFO     8000 11892
2025-05-06 23:54:43,674 INFO     9000 11892
2025-05-06 23:54:52,675 INFO     10000 11892
2025-05-06 23:55:01,681 INFO     11000 11892
2025-05-06 23:55:11,679 INFO     >>>>> Generator: Training
2025-05-06 23:55:12,122 INFO     -------------------------
2025-05-06 23:55:12,122 INFO     | Post-train Generator
2025-05-06 23:55:12,122 INFO     -------------------------
2025-05-06 23:55:12,122 INFO     >>>>> Generator: Training
2025-05-06 23:55:16,471 INFO     [E1000] Total: 0.981008 | Main: 1.143603 | Aux: 0.680737
2025-05-06 23:55:16,471 INFO     -------------------------
2025-05-06 23:55:16,471 INFO     | Beam Search Best Rules
2025-05-06 23:55:16,471 INFO     -------------------------
2025-05-06 23:55:16,472 INFO     >>>>> Generator: Rule generation with beam search
2025-05-06 23:55:16,734 INFO     >>>>> Generator: Rule generation with beam search
2025-05-06 23:55:18,262 INFO     >>>>> Generator: Rule generation with beam search
2025-05-06 23:55:30,034 INFO     >>>>> Generator: Rule generation with beam search
2025-05-06 23:55:38,227 INFO     >>>>> Generator: Rule generation with beam search
2025-05-06 23:55:43,694 INFO     -------------------------
2025-05-06 23:55:43,694 INFO     | Train Final Predictor+
2025-05-06 23:55:43,694 INFO     -------------------------
2025-05-06 23:55:43,700 INFO     Predictor+: read 18420 rules from list.
2025-05-06 23:55:43,758 INFO     Predictor+: read 18420 rules from list.
2025-05-06 23:55:43,885 INFO     Preprocess training set
2025-05-06 23:55:43,892 INFO     -------------------------
2025-05-06 23:55:43,892 INFO     | Iteration: 1/1
2025-05-06 23:55:43,892 INFO     -------------------------
2025-05-06 23:55:43,892 INFO     >>>>> Predictor: Training
2025-05-06 23:56:33,357 INFO     100 11892 8.668314 606488.0
2025-05-06 23:57:21,829 INFO     200 11892 7.428583 606488.0
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/emma/emma/bilab_archive/polly/RNNLogic/src/run_rnnlogic.py", line 181, in <module>
[rank0]:     main(parse_args())
[rank0]:   File "/home/emma/emma/bilab_archive/polly/RNNLogic/src/run_rnnlogic.py", line 163, in main
[rank0]:     solver_p.train(**cfg.predictorplus.train)
[rank0]:   File "/home/emma/emma/bilab_archive/polly/RNNLogic/src/trainer.py", line 86, in train
[rank0]:     logits, mask = model(all_h, all_r, edges_to_remove)
[rank0]:   File "/home/emma/polly_env_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/emma/polly_env_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/emma/polly_env_py39/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1643, in forward
[rank0]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank0]:   File "/home/emma/polly_env_py39/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1459, in _run_ddp_forward
[rank0]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank0]:   File "/home/emma/polly_env_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/emma/polly_env_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/emma/emma/bilab_archive/polly/RNNLogic/src/predictors.py", line 253, in forward
[rank0]:     output = self.rule_to_entity(rule_count, rule_emb, batch_id_of_candidate)
[rank0]:   File "/home/emma/polly_env_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/emma/polly_env_py39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/emma/emma/bilab_archive/polly/RNNLogic/src/layers.py", line 72, in forward
[rank0]:     features = (message * weight).sum(1)
[rank0]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.80 GiB. GPU 0 has a total capacity of 11.72 GiB of which 5.78 GiB is free. Process 39464 has 180.00 MiB memory in use. Including non-PyTorch memory, this process has 5.69 GiB memory in use. Of the allocated memory 503.01 MiB is allocated by PyTorch, and 4.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W506 23:58:04.096599418 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
W0506 23:58:05.779156 39440 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 39464 closing signal SIGTERM
E0506 23:58:05.993771 39440 torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 0 (pid: 39463) of binary: /home/emma/polly_env_py39/bin/python3.9
Traceback (most recent call last):
  File "/home/emma/polly_env_py39/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/emma/polly_env_py39/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
  File "/home/emma/polly_env_py39/lib/python3.9/site-packages/torch/distributed/run.py", line 919, in main
    run(args)
  File "/home/emma/polly_env_py39/lib/python3.9/site-packages/torch/distributed/run.py", line 910, in run
    elastic_launch(
  File "/home/emma/polly_env_py39/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/emma/polly_env_py39/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
run_rnnlogic.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-05-06_23:58:05
  host      : emma-System-Product-Name
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 39463)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
